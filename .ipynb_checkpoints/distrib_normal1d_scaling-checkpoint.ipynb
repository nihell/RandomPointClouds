{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b443743a-4a57-46f8-b6f3-20ea71cdce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi as gd\n",
    "from gudhi import representations\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import matplotlib.pyplot as plt\n",
    "import pingouin as pg\n",
    "import scipy.stats as st\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c8cddd-0926-4379-888d-7472925371d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pi(data):\n",
    "    pi0s = []\n",
    "    for dat in data:\n",
    "        ac = gd.AlphaComplex(points = dat.reshape(-1,1))\n",
    "        st = ac.create_simplex_tree()\n",
    "        st.compute_persistence()\n",
    "        pi0s.append(st.persistence_intervals_in_dimension(0))\n",
    "    return pi0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414e6cfa-391c-4c4d-a780-7a12fc8ae83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_statistics(RV, N, n_samples, n_samples_test, q=0.95):\n",
    "    samples = [RV.rvs(N) for i in range(n_samples)]\n",
    "    #if standarize_data:\n",
    "    samples_std = [standarize(sample) for sample in samples]\n",
    "    samples = samples_std.copy()\n",
    "    \n",
    "    pi0s = get_pi(samples)\n",
    "    W1D = gd.representations.WassersteinDistance(n_jobs=-1, order=wasserstein_order, internal_p=wasserstein_p)\n",
    "    W1_train = W1D.fit_transform(pi0s)\n",
    "\n",
    "    samples_test = [RV.rvs(N) for i in range(n_samples_test)]\n",
    "    #if standarize_data:\n",
    "    samples_test_std = [standarize(sample) for sample in samples_test]\n",
    "    samples_test = samples_test_std.copy()\n",
    "    \n",
    "    pi0s_test = get_pi(samples_test)\n",
    "    W1_test = W1D.transform(pi0s_test)\n",
    "\n",
    "    dmean = np.mean(W1_test, axis=1)\n",
    "    dmin = np.min(W1_test, axis=1)\n",
    "    dmax = np.max(W1_test, axis=1)\n",
    "    dq = np.quantile(W1_test, q=0.9, axis=1)\n",
    "    qmean = np.quantile(dmean, q)\n",
    "    qmin = np.quantile(dmin, q)\n",
    "    qmax = np.quantile(dmax, q)\n",
    "    qq = np.quantile(dq, q)\n",
    "    return W1D, qmin, qmean, qmax, qq, dmin, dmean, dmax, dq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2247db52-02ac-414b-953c-fdb331659a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize(X):\n",
    "    return (X-np.mean(X))/np.std(X)\n",
    "\n",
    "def topo_test(samples, W1D, qmin, qmean, qmax, qq):\n",
    "    #if standarize_data:\n",
    "    samples_std = [standarize(sample) for sample in samples]\n",
    "    samples = samples_std.copy()\n",
    "    \n",
    "    pi0s = get_pi(samples)\n",
    "    W1_test = W1D.transform(pi0s)\n",
    "    dmin = np.min(W1_test, axis=1)\n",
    "    dmax = np.max(W1_test, axis=1)\n",
    "    dmean = np.mean(W1_test, axis=1)\n",
    "    dq = np.quantile(W1_test, q=0.9, axis=1) # takie samo q jak w train_statistcs\n",
    "    \n",
    "    is_normal_min = dmin < qmin\n",
    "    is_normal_mean = dmean < qmean\n",
    "    is_normal_max = dmax < qmax\n",
    "    is_normal_q = dq < qq\n",
    "    \n",
    "    p_empirical_min = np.sum(is_normal_min)/len(is_normal_min)\n",
    "    p_empirical_mean = np.sum(is_normal_mean)/len(is_normal_mean)\n",
    "    p_empirical_max = np.sum(is_normal_max)/len(is_normal_max)\n",
    "    p_empirical_q = np.sum(is_normal_q)/len(is_normal_q)\n",
    "    return p_empirical_min, p_empirical_mean, p_empirical_max, p_empirical_q\n",
    "\n",
    "def normality_tests(samples):\n",
    "    def anderson(sample):\n",
    "        anderson_out = st.anderson(sample, 'norm')\n",
    "        return anderson_out.statistic < anderson_out.critical_values[2]\n",
    "\n",
    "    shapiro = [st.shapiro(sample).pvalue >0.05 for sample in samples]\n",
    "    ks = [st.kstest(sample, 'norm').pvalue >0.05 for sample in samples]\n",
    "    cvm = [st.cramervonmises(sample, 'norm').pvalue >0.05 for sample in samples]\n",
    "    ad = [anderson(sample) for sample in samples]\n",
    "    \n",
    "    shapiro = np.sum(shapiro)/len(shapiro)\n",
    "    ks = np.sum(ks)/len(ks)\n",
    "    ad = np.sum(ad)/len(ad)\n",
    "    cvm = np.sum(cvm)/len(cvm)\n",
    "    return shapiro, ks, ad, cvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa80de87-000b-4179-b269-92c6367dfb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate other distributions to measure test power\n",
    "# first check normal distribution\n",
    "def empirical_test_power(RV, W1D, qmin, qmean, qmax, qq, N=100, n_samples=250):\n",
    "    samples_topo = [RV.rvs(N) for i in range(n_samples)]\n",
    "    mu = RV.stats('m')\n",
    "    std = np.sqrt(RV.stats('v'))\n",
    "    samples = [(sample-mu)/std for sample in samples_topo]\n",
    "    topo_min, topo_mean, topo_max, topo_q = topo_test(samples_topo, W1D, qmin, qmean, qmax, qq)\n",
    "    power_shapiro, power_ks, power_ad, power_cvm = normality_tests(samples)\n",
    "    return topo_min, topo_mean, topo_max, topo_q, power_shapiro, power_ks, power_ad, power_cvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab6947ef-dde3-4ee2-a837-af29ab086600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.semanticscholar.org/paper/Power-comparisons-of-Shapiro-Wilk-%2C-%2C-Lilliefors-Razali-Wah/dcdc0a0be7d65257c4e6a9117f69e246fb227423\n",
    "\n",
    "rv_normal = st.norm()\n",
    "rv_normal2_2 = st.norm(2,2)\n",
    "rv_beta2_2 = st.beta(2, 2)\n",
    "rv_beta5_5 = st.beta(5, 5)\n",
    "rv_beta10_10 = st.beta(10, 10)\n",
    "rv_laplace = st.laplace()\n",
    "rv_uniform = st.uniform()\n",
    "rv_t3 = st.t(df=3)\n",
    "rv_t5 = st.t(df=5)\n",
    "rv_t7 = st.t(df=7)\n",
    "rv_t10 = st.t(df=10)\n",
    "rv_gamma10_1 = st.gamma(10,1)\n",
    "rv_gamma20_1 = st.gamma(20,1)\n",
    "rv_gamma4_5 = st.gamma(4,5)\n",
    "rv_chisq4 = st.chi2(df=4)\n",
    "rv_chisq10 = st.chi2(df=10)\n",
    "rv_lorentz = st.cauchy()\n",
    "\n",
    "wasserstein_p = 1\n",
    "wasserstein_order = 1\n",
    "standarize_data = True\n",
    "\n",
    "outputfilename = f'results/{wasserstein_p}_{wasserstein_order}_{standarize_data}_distrib_std'\n",
    "\n",
    "rvs = [rv_normal, rv_normal2_2, rv_beta2_2, rv_beta5_5, rv_beta10_10, rv_laplace, rv_uniform, rv_t3, rv_t5, rv_t7, rv_t10, \n",
    "       rv_gamma10_1, rv_gamma20_1, rv_gamma4_5, rv_chisq4, rv_chisq10, rv_lorentz]\n",
    "rv_names = ['Normal01', 'Normal22', 'Beta22', 'Beta55', 'Beta1010', 'Laplace', 'Uniform', 't3', 't5', 't7', 't10', \n",
    "            'G10_1', 'G20_1', 'G4_5', 'ChiSq4', 'ChiSq10', 'Lorentz']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e5ca1-79c2-4206-8da2-42f73cc929e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=10 rv_name=Normal01\n",
      "N=10 rv_name=Normal22\n",
      "N=10 rv_name=Beta22\n",
      "N=10 rv_name=Beta55\n",
      "N=10 rv_name=Beta1010\n",
      "N=10 rv_name=Laplace\n",
      "N=10 rv_name=Uniform\n",
      "N=10 rv_name=t3\n",
      "N=10 rv_name=t5\n",
      "N=10 rv_name=t7\n",
      "N=10 rv_name=t10\n",
      "N=10 rv_name=G10_1\n",
      "N=10 rv_name=G20_1\n",
      "N=10 rv_name=G4_5\n",
      "N=10 rv_name=ChiSq4\n",
      "N=10 rv_name=ChiSq10\n",
      "N=10 rv_name=Lorentz\n",
      "N=20 rv_name=Normal01\n",
      "N=20 rv_name=Normal22\n",
      "N=20 rv_name=Beta22\n",
      "N=20 rv_name=Beta55\n",
      "N=20 rv_name=Beta1010\n",
      "N=20 rv_name=Laplace\n",
      "N=20 rv_name=Uniform\n",
      "N=20 rv_name=t3\n",
      "N=20 rv_name=t5\n",
      "N=20 rv_name=t7\n",
      "N=20 rv_name=t10\n",
      "N=20 rv_name=G10_1\n",
      "N=20 rv_name=G20_1\n",
      "N=20 rv_name=G4_5\n",
      "N=20 rv_name=ChiSq4\n",
      "N=20 rv_name=ChiSq10\n",
      "N=20 rv_name=Lorentz\n",
      "N=30 rv_name=Normal01\n",
      "N=30 rv_name=Normal22\n",
      "N=30 rv_name=Beta22\n",
      "N=30 rv_name=Beta55\n",
      "N=30 rv_name=Beta1010\n",
      "N=30 rv_name=Laplace\n",
      "N=30 rv_name=Uniform\n",
      "N=30 rv_name=t3\n",
      "N=30 rv_name=t5\n",
      "N=30 rv_name=t7\n",
      "N=30 rv_name=t10\n",
      "N=30 rv_name=G10_1\n",
      "N=30 rv_name=G20_1\n",
      "N=30 rv_name=G4_5\n",
      "N=30 rv_name=ChiSq4\n",
      "N=30 rv_name=ChiSq10\n",
      "N=30 rv_name=Lorentz\n",
      "N=50 rv_name=Normal01\n",
      "N=50 rv_name=Normal22\n",
      "N=50 rv_name=Beta22\n",
      "N=50 rv_name=Beta55\n",
      "N=50 rv_name=Beta1010\n",
      "N=50 rv_name=Laplace\n",
      "N=50 rv_name=Uniform\n",
      "N=50 rv_name=t3\n",
      "N=50 rv_name=t5\n",
      "N=50 rv_name=t7\n",
      "N=50 rv_name=t10\n",
      "N=50 rv_name=G10_1\n",
      "N=50 rv_name=G20_1\n",
      "N=50 rv_name=G4_5\n",
      "N=50 rv_name=ChiSq4\n",
      "N=50 rv_name=ChiSq10\n",
      "N=50 rv_name=Lorentz\n",
      "N=100 rv_name=Normal01\n",
      "N=100 rv_name=Normal22\n",
      "N=100 rv_name=Beta22\n",
      "N=100 rv_name=Beta55\n",
      "N=100 rv_name=Beta1010\n",
      "N=100 rv_name=Laplace\n",
      "N=100 rv_name=Uniform\n",
      "N=100 rv_name=t3\n",
      "N=100 rv_name=t5\n",
      "N=100 rv_name=t7\n",
      "N=100 rv_name=t10\n",
      "N=100 rv_name=G10_1\n",
      "N=100 rv_name=G20_1\n"
     ]
    }
   ],
   "source": [
    "n_samples = 500\n",
    "mc_loops = 750\n",
    "results = defaultdict(list)\n",
    "resuts_stats = {}\n",
    "\n",
    "for N in [10, 20, 30, 50, 100, 150, 200, 250, 300, 400, 500]:\n",
    "    # compute the  distance matrix for normal distribution for given data size N\n",
    "    W1D, qmin, qmean, qmax, qq, dmin, dmean, dmax, dq = train_statistics(rv_normal, N=N, n_samples=n_samples, n_samples_test=750, q=0.95)\n",
    "    resuts_stats[N] = [W1D, qmin, qmean, qmax, qq, dmin, dmean, dmax, dq]\n",
    "    \n",
    "    for rv, rv_name in zip(rvs, rv_names):\n",
    "        print(f'N={N} rv_name={rv_name}')\n",
    "        results[rv_name].append([N, *empirical_test_power(RV=rv, W1D=W1D, qmin=qmin, qmean=qmean, qmax=qmax, qq=qq, N=N, n_samples=mc_loops)])\n",
    "    \n",
    "    np.save(outputfilename+'.npy', results)\n",
    "    np.save(outputfilename+'_stats.npy', resuts_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348134bd-5ffd-4665-9b2b-e9efc2c05f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dist_name in results.keys():\n",
    "#     data = results[dist_name]\n",
    "#     data = np.array(data)\n",
    "#     plt.plot(data[:, 0], 1-data[:, 1], 'o-', label='Topo')\n",
    "#     plt.plot(data[:, 0], 1-data[:, 2], 'o-', label='Shapiro')\n",
    "#     plt.plot(data[:, 0], 1-data[:, 3], 'o-', label='KS')\n",
    "#     plt.plot(data[:, 0], 1-data[:, 4], 'o-', label='Anderson-Darling')\n",
    "#     plt.plot(data[:, 0], 1-data[:, 5], 'o-', label='Crammer-von-Misses')\n",
    "#     plt.xlabel('Sample size')\n",
    "#     plt.ylabel('Test power')\n",
    "#     plt.title(f'Distribution = {dist_name}')\n",
    "#     plt.legend()\n",
    "#     plt.savefig(outputfilename+'_'+dist_name+'.png')\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
