{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b443743a-4a57-46f8-b6f3-20ea71cdce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi as gd\n",
    "from gudhi import representations\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import matplotlib.pyplot as plt\n",
    "import pingouin as pg\n",
    "import scipy.stats as st\n",
    "from collections import defaultdict\n",
    "import ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c1dac1-74e2-48b4-9f7e-329d4ba378fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56dde559-fbe1-4ddc-bb9f-e347cc9c8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_distance_matrix(samples1, samples2, lmbda):\n",
    "    dists  = np.zeros((len(samples1), len(samples2)))\n",
    "    if samples1==samples2:\n",
    "        for i in range(0,len(samples1)):\n",
    "            for j in range(0,i):\n",
    "                #print(samples1[i])\n",
    "                #print(samples2[j])\n",
    "                M = ot.dist(samples1[i].reshape(-1,1), samples2[j].reshape(-1,1))\n",
    "                em1 = np.ones((len(samples1[i]),))/len(samples1[i])\n",
    "                em2 = np.ones((len(samples2[j]),))/len(samples2[j])\n",
    "                T = ot.sinkhorn(em1, em2, M, lmbda)\n",
    "                d = np.inner(T.flatten(), M.flatten())\n",
    "                dists[i][j] = d\n",
    "        dists = dists+dists.T\n",
    "    else:\n",
    "        for i in range(0,len(samples1)):\n",
    "            for j in range(0,len(samples2)):\n",
    "                #print(samples1[i])\n",
    "                #print(samples2[j])\n",
    "                M = ot.dist(samples1[i].reshape(-1,1), samples2[j].reshape(-1,1))\n",
    "                em1 = np.ones((len(samples1[i]),))/len(samples1[i])\n",
    "                em2 = np.ones((len(samples2[j]),))/len(samples2[j])\n",
    "                T = ot.sinkhorn(em1, em2, M, lmbda)\n",
    "                d = np.inner(T.flatten(), M.flatten())\n",
    "                dists[i][j] = d\n",
    "        \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "414e6cfa-391c-4c4d-a780-7a12fc8ae83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_statistics(RV, N, n_samples, n_samples_test, q=0.95):\n",
    "    samples = [RV.rvs(N) for i in range(n_samples)]\n",
    "    #if standarize_data:\n",
    "    samples_std = [standarize(sample) for sample in samples]\n",
    "    samples = samples_std.copy()\n",
    "    \n",
    "    W1_train = sinkhorn_distance_matrix(samples, samples, 1e-1)\n",
    "\n",
    "    samples_test = [RV.rvs(N) for i in range(n_samples_test)]\n",
    "    #if standarize_data:\n",
    "    samples_test_std = [standarize(sample) for sample in samples_test]\n",
    "    samples_test = samples_test_std.copy()\n",
    "    \n",
    "    W1_test = sinkhorn_distance_matrix(samples, samples_test, 1e-1)\n",
    "\n",
    "    dmean = np.mean(W1_test, axis=1)\n",
    "    dmin = np.min(W1_test, axis=1)\n",
    "    dmax = np.max(W1_test, axis=1)\n",
    "    dq = np.quantile(W1_test, q=0.9, axis=1)\n",
    "    qmean = np.quantile(dmean, q)\n",
    "    qmin = np.quantile(dmin, q)\n",
    "    qmax = np.quantile(dmax, q)\n",
    "    qq = np.quantile(dq, q)\n",
    "    return samples, qmin, qmean, qmax, qq, dmin, dmean, dmax, dq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2247db52-02ac-414b-953c-fdb331659a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize(X):\n",
    "    return (X-np.mean(X))/np.std(X)\n",
    "\n",
    "def topo_test(samples, eccs, qmin, qmean, qmax, qq):\n",
    "    #if standarize_data:\n",
    "    samples_std = [standarize(sample) for sample in samples]\n",
    "    samples = samples_std.copy()\n",
    "    \n",
    "    #print(\"topo_test before ecc\")\n",
    "    #print(\"topo_test: got eccs, now compute distances\")\n",
    "    W1_test = sinkhorn_distance_matrix(eccs, samples, 1e-1)\n",
    "    #print(\"topo_test: distances computed\")\n",
    "    dmin = np.min(W1_test, axis=1)\n",
    "    dmax = np.max(W1_test, axis=1)\n",
    "    dmean = np.mean(W1_test, axis=1)\n",
    "    dq = np.quantile(W1_test, q=0.9, axis=1) # takie samo q jak w train_statistcs\n",
    "    \n",
    "    is_normal_min = dmin < qmin\n",
    "    is_normal_mean = dmean < qmean\n",
    "    is_normal_max = dmax < qmax\n",
    "    is_normal_q = dq < qq\n",
    "    \n",
    "    p_empirical_min = np.sum(is_normal_min)/len(is_normal_min)\n",
    "    p_empirical_mean = np.sum(is_normal_mean)/len(is_normal_mean)\n",
    "    p_empirical_max = np.sum(is_normal_max)/len(is_normal_max)\n",
    "    p_empirical_q = np.sum(is_normal_q)/len(is_normal_q)\n",
    "    #print(\"topo_test done\")\n",
    "    return p_empirical_min, p_empirical_mean, p_empirical_max, p_empirical_q\n",
    "\n",
    "def normality_tests(samples):\n",
    "    def anderson(sample):\n",
    "        anderson_out = st.anderson(sample, 'norm')\n",
    "        return anderson_out.statistic < anderson_out.critical_values[2]\n",
    "\n",
    "    shapiro = [st.shapiro(sample).pvalue >0.05 for sample in samples]\n",
    "    ks = [st.kstest(sample, 'norm').pvalue >0.05 for sample in samples]\n",
    "    cvm = [st.cramervonmises(sample, 'norm').pvalue >0.05 for sample in samples]\n",
    "    ad = [anderson(sample) for sample in samples]\n",
    "    \n",
    "    shapiro = np.sum(shapiro)/len(shapiro)\n",
    "    ks = np.sum(ks)/len(ks)\n",
    "    ad = np.sum(ad)/len(ad)\n",
    "    cvm = np.sum(cvm)/len(cvm)\n",
    "    return shapiro, ks, ad, cvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa80de87-000b-4179-b269-92c6367dfb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate other distributions to measure test power\n",
    "# first check normal distribution\n",
    "def empirical_test_power(RV, eccs, qmin, qmean, qmax, qq, N=100, n_samples=250):\n",
    "    samples_topo = [RV.rvs(N) for i in range(n_samples)]\n",
    "    mu = RV.stats('m')\n",
    "    std = np.sqrt(RV.stats('v'))\n",
    "    samples = [(sample-mu)/std for sample in samples_topo]\n",
    "    #print(\"in empirical_test_power, after standardizing\")\n",
    "    topo_min, topo_mean, topo_max, topo_q = topo_test(samples_topo, eccs, qmin, qmean, qmax, qq)\n",
    "    #print(\"in empirical_test_power, after topo_test\")\n",
    "    power_shapiro, power_ks, power_ad, power_cvm = normality_tests(samples)\n",
    "    #print(\"done with empirical_test_power\")\n",
    "    return topo_min, topo_mean, topo_max, topo_q, power_shapiro, power_ks, power_ad, power_cvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6947ef-dde3-4ee2-a837-af29ab086600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.semanticscholar.org/paper/Power-comparisons-of-Shapiro-Wilk-%2C-%2C-Lilliefors-Razali-Wah/dcdc0a0be7d65257c4e6a9117f69e246fb227423\n",
    "\n",
    "rv_normal = st.norm()\n",
    "rv_normal2_2 = st.norm(2,2)\n",
    "rv_beta2_2 = st.beta(2, 2)\n",
    "rv_beta5_5 = st.beta(5, 5)\n",
    "rv_beta10_10 = st.beta(10, 10)\n",
    "rv_laplace = st.laplace()\n",
    "rv_uniform = st.uniform()\n",
    "rv_t3 = st.t(df=3)\n",
    "rv_t5 = st.t(df=5)\n",
    "rv_t7 = st.t(df=7)\n",
    "rv_t10 = st.t(df=10)\n",
    "rv_gamma10_1 = st.gamma(10,1)\n",
    "rv_gamma20_1 = st.gamma(20,1)\n",
    "rv_gamma4_5 = st.gamma(4,5)\n",
    "rv_chisq4 = st.chi2(df=4)\n",
    "rv_chisq10 = st.chi2(df=10)\n",
    "rv_lorentz = st.cauchy()\n",
    "\n",
    "wasserstein_p = 1\n",
    "wasserstein_order = 1\n",
    "standarize_data = True\n",
    "\n",
    "outputfilename = f'results/{standarize_data}_distrib_std_Sinkhorn'\n",
    "\n",
    "rvs = [rv_normal, rv_normal2_2, rv_beta2_2, rv_beta5_5, rv_beta10_10, rv_laplace, rv_uniform, rv_t3, rv_t5, rv_t7, rv_t10, \n",
    "       rv_gamma10_1, rv_gamma20_1, rv_gamma4_5, rv_chisq4, rv_chisq10, rv_lorentz]\n",
    "rv_names = ['Normal01', 'Normal22', 'Beta22', 'Beta55', 'Beta1010', 'Laplace', 'Uniform', 't3', 't5', 't7', 't10', \n",
    "            'G10_1', 'G20_1', 'G4_5', 'ChiSq4', 'ChiSq10']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b1e5ca1-79c2-4206-8da2-42f73cc929e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29383/4193370693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mN\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#, 250, 300, 400, 500]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# compute the  distance matrix for normal distribution for given data size N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0meccs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrv_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m750\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mresuts_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meccs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_29383/3597162529.py\u001b[0m in \u001b[0;36mtrain_statistics\u001b[0;34m(RV, N, n_samples, n_samples_test, q)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mW1_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msinkhorn_distance_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msamples_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mRV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_29383/3475521611.py\u001b[0m in \u001b[0;36msinkhorn_distance_matrix\u001b[0;34m(samples1, samples2, lmbda)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mem1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mem2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msinkhorn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mem2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mdists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/ot/bregman.py\u001b[0m in \u001b[0;36msinkhorn\u001b[0;34m(a, b, M, reg, method, numItermax, stopThr, verbose, log, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sinkhorn'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         return sinkhorn_knopp(a, b, M, reg, numItermax=numItermax,\n\u001b[0m\u001b[1;32m    136\u001b[0m                               \u001b[0mstopThr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstopThr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                               **kwargs)\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/ot/bregman.py\u001b[0m in \u001b[0;36msinkhorn_knopp\u001b[0;34m(a, b, M, reg, numItermax, stopThr, verbose, log, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         if (nx.any(KtransposeU == 0)\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0;32mor\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m                 or nx.any(nx.isinf(u)) or nx.any(nx.isinf(v))):\n\u001b[1;32m    399\u001b[0m             \u001b[0;31m# we have reached the machine precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/ot/backend.py\u001b[0m in \u001b[0;36many\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36many\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_samples = 500\n",
    "mc_loops = 750\n",
    "results = defaultdict(list)\n",
    "resuts_stats = {}\n",
    "\n",
    "for N in [30, 50, 100, 150, 200]:#, 250, 300, 400, 500]:\n",
    "    # compute the  distance matrix for normal distribution for given data size N\n",
    "    eccs, qmin, qmean, qmax, qq, dmin, dmean, dmax, dq = train_statistics(rv_normal, N=N, n_samples=n_samples, n_samples_test=750, q=0.95)\n",
    "    resuts_stats[N] = [eccs, qmin, qmean, qmax, qq, dmin, dmean, dmax, dq]\n",
    "    \n",
    "    for rv, rv_name in zip(rvs, rv_names):\n",
    "        print(f'N={N} rv_name={rv_name}')\n",
    "        results[rv_name].append([N, *empirical_test_power(RV=rv, eccs=eccs, qmin=qmin, qmean=qmean, qmax=qmax, qq=qq, N=N, n_samples=mc_loops)])\n",
    "    \n",
    "    np.save(outputfilename+'.npy', results)\n",
    "    np.save(outputfilename+'_stats.npy', resuts_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348134bd-5ffd-4665-9b2b-e9efc2c05f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dist_name in results.keys():\n",
    "    data = results[dist_name]\n",
    "    data = np.array(data)\n",
    "    plt.plot(data[:, 0], 1-data[:, 1], 'o-', label='Sinkhorn')\n",
    "    plt.plot(data[:, 0], 1-data[:, 2], 'o-', label='Shapiro')\n",
    "    plt.plot(data[:, 0], 1-data[:, 3], 'o-', label='KS')\n",
    "    plt.plot(data[:, 0], 1-data[:, 4], 'o-', label='Anderson-Darling')\n",
    "    plt.plot(data[:, 0], 1-data[:, 5], 'o-', label='Crammer-von-Misses')\n",
    "    plt.xlabel('Sample size')\n",
    "    plt.ylabel('Test power')\n",
    "    plt.title(f'Distribution = {dist_name}')\n",
    "    plt.legend()\n",
    "    plt.savefig(outputfilename+'_'+dist_name+'_Sinkhorn.png')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
